# -- coding: utf-8 --
#!/usr/bin/env python
import gradio as gr
from PIL import Image
import sys
import os

sys.path.append(os.getcwd())
import json
import numpy as np
from pathlib import Path
import io
import hashlib
import requests
import base64
import pandas as pd
from sample_t2i import inferencer
from mllm.dialoggen_demo import init_dialoggen_model, eval_model

SIZES = {
    "æ­£æ–¹å½¢(square, 1024x1024)": (1024, 1024),
    "é£æ™¯(landscape, 1280x768)": (768, 1280),
    "äººåƒ(portrait, 768x1280)": (1280, 768),
}

global_seed = np.random.randint(0, 10000)


# Helper Functions
def image_to_base64(image_path):
    with open(image_path, "rb") as image_file:
        encoded_image = base64.b64encode(image_file.read()).decode()
    return encoded_image


def get_strings(lang):
    lang_file = Path(f"app/lang/{lang}.csv")
    strings = pd.read_csv(lang_file, header=0)
    strings = strings.set_index("key")["value"].to_dict()
    return strings


def get_image_md5(image):
    image_data = io.BytesIO()
    image.save(image_data, format="PNG")
    image_data = image_data.getvalue()
    md5_hash = hashlib.md5(image_data).hexdigest()
    return md5_hash


# mllmè°ƒç”¨
def request_dialogGen(
    server_url="http://0.0.0.0:8080",
    history_messages=[],
    question="ç”»ä¸€ä¸ªæœ¨åˆ¶çš„é¸Ÿ",
    image="",
):
    if image != "":
        image = base64.b64encode(open(image, "rb").read()).decode()
    print("history_messages before request", history_messages)
    headers = {"accept": "application/json", "Content-Type": "application/json"}
    data = {
        "text": question,
        "image": image,  # "imageä¸ºç©ºå­—ç¬¦ä¸²ï¼Œåˆ™è¿›è¡Œæ–‡æœ¬å¯¹è¯"
        "history": history_messages,
    }
    response = requests.post(server_url, headers=headers, json=data)
    print("response", response)
    response = response.json()
    print(response)
    response_text = response["result"]
    history_messages = response["history"]
    print("history_messages before request", history_messages)
    return history_messages, response_text


# ç”»å›¾
def image_generation(prompt, infer_steps, seed, image_size):
    print(
        f"prompt sent to T2I model: {prompt}, infer_steps: {infer_steps}, seed: {seed}, size: {image_size}"
    )
    height, width = SIZES[image_size]
    results = gen.predict(
        prompt,
        height=height,
        width=width,
        seed=seed,
        infer_steps=infer_steps,
        batch_size=1,
    )
    image = results["images"][0]
    file_name = get_image_md5(image)
    # Save images
    save_dir = Path("results")
    save_dir.mkdir(exist_ok=True)
    save_path = f"results/multiRound_{file_name}.png"
    image.save(save_path)
    encoded_image = image_to_base64(save_path)

    return encoded_image


# å›¾æ–‡å¯¹è¯
def chat(history_messages, input_text):

    history_messages, response_text = request_dialogGen(
        history_messages=history_messages, question=input_text
    )
    return history_messages, response_text


#
def pipeline(input_text, state, infer_steps, seed, image_size):

    # å¿½ç•¥ç©ºè¾“å…¥
    if len(input_text) == 0:
        return state, state[0]

    conversation = state[0]
    history_messages = state[1]

    system_prompt = "è¯·å…ˆåˆ¤æ–­ç”¨æˆ·çš„æ„å›¾ï¼Œè‹¥ä¸ºç”»å›¾åˆ™åœ¨è¾“å‡ºå‰åŠ å…¥<ç”»å›¾>:"
    print(f"input history:{history_messages}")
    if not isinstance(history_messages, list) and len(history_messages.messages) >= 2:
        response, history_messages = enhancer(
            input_text, return_history=True, history=history_messages, skip_special=True
        )
    else:
        response, history_messages = enhancer(
            input_text,
            return_history=True,
            history=history_messages,
            skip_special=False,
        )

    history_messages.messages[-1][-1] = response

    if "<ç”»å›¾>" in response:
        intention_draw = True
    else:
        intention_draw = False

    print(f"response:{response}")
    print("-" * 80)
    print(f"history_messages:{history_messages}")
    print(f"intention_draw:{intention_draw}")
    if intention_draw:
        prompt = response.split("<ç”»å›¾>")[-1]
        # ç”»å›¾
        image_url = image_generation(prompt, infer_steps, seed, image_size)
        response = f'<img src="data:image/png;base64,{image_url}" style="display: inline-block;"><p style="font-size: 14px; color: #555; margin-top: 0;">{prompt}</p>'
    conversation += [((input_text, response))]
    return [conversation, history_messages], conversation


# é¡µé¢è®¾è®¡
def upload_image(state, image_input):
    conversation = state[0]
    history_messages = state[1]
    input_image = Image.open(image_input.name).resize((224, 224)).convert("RGB")
    input_image.save(image_input.name)  # Overwrite with smaller image.
    system_prompt = "è¯·å…ˆåˆ¤æ–­ç”¨æˆ·çš„æ„å›¾ï¼Œè‹¥ä¸ºç”»å›¾åˆ™åœ¨è¾“å‡ºå‰åŠ å…¥<ç”»å›¾>:"
    history_messages, response = request_dialogGen(
        question="è¿™å¼ å›¾æè¿°äº†ä»€ä¹ˆï¼Ÿ",
        history_messages=history_messages,
        image=image_input.name,
    )
    conversation += [
        (
            f'<img src="./file={image_input.name}"  style="display: inline-block;">',
            response,
        )
    ]
    print("conversation", conversation)
    print("history_messages after uploading image", history_messages)
    return [conversation, history_messages], conversation


def reset():
    global global_seed
    global_seed = np.random.randint(0, 10000)
    return [[], []], []


def reset_last(state):
    conversation, history = state[0], state[1]
    conversation = conversation[:-1]
    history.messages = history.messages[:-2]
    return [conversation, history], conversation


if __name__ == "__main__":

    # Initialize dialoggen and HunyuanDiT model
    args, gen, enhancer = inferencer()
    strings = get_strings(args.lang)

    css = """
        #chatbot { min-height: 800px; }
        #save-btn {
            background-image: linear-gradient(to right bottom, rgba(130,217,244, 0.9), rgba(158,231,214, 1.0));
        }
        #save-btn:hover {
            background-image: linear-gradient(to right bottom, rgba(110,197,224, 0.9), rgba(138,211,194, 1.0));
        }
        #share-btn {
            background-image: linear-gradient(to right bottom, rgba(130,217,244, 0.9), rgba(158,231,214, 1.0));
        }
        #share-btn:hover {
            background-image: linear-gradient(to right bottom, rgba(110,197,224, 0.9), rgba(138,211,194, 1.0));
        }
        #gallery { z-index: 999999; }
        #gallery img:hover {transform: scale(2.3); z-index: 999999; position: relative; padding-right: 30%; padding-bottom: 30%;}
        #gallery button img:hover {transform: none; z-index: 999999; position: relative; padding-right: 0; padding-bottom: 0;}
        @media (hover: none) {
            #gallery img:hover {transform: none; z-index: 999999; position: relative; padding-right: 0; 0;}
        }
        .html2canvas-container { width: 3000px !important; height: 3000px !important; }
    """

    with gr.Blocks(css=css) as demo:
        DESCRIPTION = """# <a style="color: black; text-decoration: none;">å¤šè½®å¯¹è¯ç»˜å›¾ Multi-turn Text2Image Generation</a>
            ä½ å¯ä»¥å‚ç…§[DialogGen](https://arxiv.org/abs/2403.08857)ï¼Œé€šè¿‡ç®€å•çš„äº¤äº’å¼è¯­å¥æ¥è¿›è¡Œå†å²å›¾ç‰‡çš„ä¿®æ”¹ï¼Œä¾‹å¦‚ï¼šä¸»ä½“ç¼–è¾‘ã€å¢åŠ ä¸»ä½“ã€åˆ é™¤ä¸»ä½“ã€èƒŒæ™¯æ›´æ¢ã€é£æ ¼è½¬æ¢ã€é•œå¤´è½¬æ¢ã€å›¾åƒåˆå¹¶ã€‚

            (You can modify historical images through simple interactive statements referred to [DialogGen](https://arxiv.org/abs/2403.08857), such as: enity edit, add object, remove object, change background, change style, change lens, and combine images. )
            
            ä¾‹å¦‚ï¼Œä¸»ä½“ç¼–è¾‘ (For example, enity edit) :
            ```none
            Round1: ç”»ä¸€ä¸ªæœ¨åˆ¶çš„é¸Ÿ
            (Round1: draw a wooden bird)
            
            Round2: å˜æˆç»ç’ƒçš„
            (Round2: turn into glass)
            ```
        """

        gr.Markdown(DESCRIPTION)
        gr_state = gr.State([[], []])  # conversation, chat_history

        with gr.Row():
            with gr.Column(scale=1, min_width=1000):
                with gr.Row():
                    chatbot = gr.Chatbot(
                        elem_id="chatbot", label="DialogGen&HunyuanDiT"
                    )
                with gr.Row():
                    infer_steps = gr.Slider(
                        label="é‡‡æ ·æ­¥æ•°(sampling steps)",
                        minimum=1,
                        maximum=200,
                        value=100,
                        step=1,
                    )
                    seed = gr.Number(
                        label="ç§å­(seed)",
                        minimum=-1,
                        maximum=1_000_000_000,
                        value=666,
                        step=1,
                        precision=0,
                    )
                    size_dropdown = gr.Dropdown(
                        choices=[
                            "æ­£æ–¹å½¢(square, 1024x1024)",
                            "é£æ™¯(landscape, 1280x768)",
                            "äººåƒ(portrait, 768x1280)",
                        ],
                        value="æ­£æ–¹å½¢(square, 1024x1024)",
                        label="å›¾ç‰‡å°ºå¯¸(Image Size)",
                    )

                with gr.Row():
                    # image_btn = gr.UploadButton("ğŸ–¼ï¸ Upload Image", file_types=["image"])
                    text_input = gr.Textbox(
                        label="æç¤ºè¯(prompt)", placeholder="è¾“å…¥æç¤ºè¯(Type a prompt)"
                    )

                    with gr.Column():
                        submit_btn = gr.Button(
                            "æäº¤(Submit)", interactive=True, variant="primary"
                        )
                        clear_last_btn = gr.Button("å›é€€(Undo)")
                        clear_btn = gr.Button("å…¨éƒ¨é‡ç½®(Reset All)")
                with gr.Row():
                    gr.Examples(
                        [
                            ["ç”»ä¸€ä¸ªæœ¨åˆ¶çš„é¸Ÿ"],
                            ["ä¸€åªå°çŒ«"],
                            [
                                "ç°å®ä¸»ä¹‰é£æ ¼ï¼Œç”»é¢ä¸»è¦æè¿°ä¸€ä¸ªå·´æ´›å…‹é£æ ¼çš„èŠ±ç“¶ï¼Œå¸¦æœ‰é‡‘è‰²çš„è£…é¥°è¾¹æ¡†ï¼ŒèŠ±ç“¶ä¸Šç››å¼€ç€å„ç§è‰²å½©é²œè‰³çš„èŠ±ï¼Œç™½è‰²èƒŒæ™¯"
                            ],
                            [
                                "ä¸€åªèªæ˜çš„ç‹ç‹¸èµ°åœ¨é˜”å¶æ ‘æ—é‡Œ, æ—è¾¹æ˜¯ä¸€æ¡å°æºª, ç»†èŠ‚çœŸå®, æ‘„å½±"
                            ],
                            ["é£æµç›´ä¸‹ä¸‰åƒå°ºï¼Œç–‘æ˜¯é“¶æ²³è½ä¹å¤©"],
                            [
                                "ä¸€åªé•¿é´çŒ«æ‰‹æŒäº®é“¶è‰²çš„å®å‰‘ï¼Œèº«ç€é“ ç”²ï¼Œçœ¼ç¥åšæ¯…ï¼Œç«™åœ¨ä¸€å †é‡‘å¸ä¸Šï¼ŒèƒŒæ™¯æ˜¯æš—è‰²è°ƒçš„æ´ç©´ï¼Œå›¾åƒä¸Šæœ‰é‡‘å¸çš„å…‰å½±ç‚¹ç¼€ã€‚"
                            ],
                            ["éº»å©†è±†è…"],
                            ["è‹å·å›­æ—"],
                            [
                                "ä¸€é¢—æ–°é²œçš„è‰è“ç‰¹å†™ï¼Œçº¢è‰²çš„å¤–è¡¨ï¼Œè¡¨é¢å¸ƒæ»¡è®¸å¤šç§å­ï¼ŒèƒŒæ™¯æ˜¯æ·¡ç»¿è‰²çš„å¶å­"
                            ],
                            ["æ¯è—¤è€æ ‘æ˜é¸¦ï¼Œå°æ¡¥æµæ°´äººå®¶"],
                            [
                                "æ¹–æ°´æ¸…æ¾ˆï¼Œå¤©ç©ºæ¹›è“ï¼Œé˜³å…‰ç¿çƒ‚ã€‚ä¸€åªä¼˜é›…çš„ç™½å¤©é¹…åœ¨æ¹–è¾¹æ¸¸æ³³ã€‚å®ƒå‘¨å›´æœ‰å‡ åªå°é¸­å­ï¼Œçœ‹èµ·æ¥éå¸¸å¯çˆ±ï¼Œæ•´ä¸ªç”»é¢ç»™äººä¸€ç§å®é™ç¥¥å’Œçš„æ„Ÿè§‰ã€‚"
                            ],
                            [
                                "ä¸€æœµé²œè‰³çš„çº¢è‰²ç«ç‘°èŠ±ï¼ŒèŠ±ç“£æ’’æœ‰ä¸€äº›æ°´ç ï¼Œæ™¶è¹å‰”é€ï¼Œç‰¹å†™é•œå¤´"
                            ],
                            ["è‡­è±†è…"],
                            ["ä¹å¯¨æ²Ÿ"],
                            ["ä¿—è¯­â€œé²¤é±¼è·ƒé¾™é—¨â€"],
                            [
                                "é£æ ¼æ˜¯å†™å®ï¼Œç”»é¢ä¸»è¦æè¿°ä¸€ä¸ªäºšæ´²æˆæ›²è‰ºæœ¯å®¶æ­£åœ¨è¡¨æ¼”ï¼Œå¥¹ç©¿ç€åä¸½çš„æˆæœï¼Œè„¸ä¸Šæˆ´ç€ç²¾è‡´çš„é¢å…·ï¼Œèº«å§¿ä¼˜é›…ï¼ŒèƒŒæ™¯æ˜¯å¤è‰²å¤é¦™çš„èˆå°ï¼Œé•œå¤´æ˜¯è¿‘æ™¯"
                            ],
                        ],
                        [text_input],
                        label=strings["examples"],
                    )
                gr.Markdown(
                    """<p style="font-size: 20px; color: #888;">powered by <a href="https://github.com/Centaurusalpha/DialogGen" target="_blank">DialogGen</a> and <a href="https://github.com/Tencent/HunyuanDiT" target="_blank">HunyuanDiT</a></p>"""
                )

        text_input.submit(
            pipeline,
            [text_input, gr_state, infer_steps, seed, size_dropdown],
            [gr_state, chatbot],
        )
        text_input.submit(lambda: "", None, text_input)  # Reset chatbox.
        submit_btn.click(
            pipeline,
            [text_input, gr_state, infer_steps, seed, size_dropdown],
            [gr_state, chatbot],
        )
        submit_btn.click(lambda: "", None, text_input)  # Reset chatbox.

        # image_btn.upload(upload_image, [gr_state, image_btn], [gr_state, chatbot])
        clear_last_btn.click(reset_last, [gr_state], [gr_state, chatbot])
        clear_btn.click(reset, [], [gr_state, chatbot])

    interface = demo
    interface.launch(server_name="0.0.0.0", server_port=443, share=False)
